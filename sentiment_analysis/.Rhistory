body1 <- content(response1, "text")
parsed_body1 <- fromJSON(body1)
data1 <- data.frame(parsed_body1$data$list, stringsAsFactors = FALSE)
data1 <- data1 %>%
select(lon, lat)
uri2 <- paste0(baseuri, topic, key, call2, radius)
response2 <- GET(uri2)
body2 <- content(response2, "text")
parsed_body2 <- fromJSON(body2)
data2 <- data.frame(parsed_body2$data$list, stringsAsFactors = FALSE)
data2 <- data2 %>%
select(lon, lat)
uri3 <- paste0(baseuri, topic, key, call3, radius)
response3 <- GET(uri3)
body3 <- content(response3, "text")
parsed_body3 <- fromJSON(body3)
data3 <- data.frame(parsed_body3$data$list, stringsAsFactors = FALSE)
data3 <- data3 %>%
select(lon, lat)
uri4 <- paste0(baseuri, topic, key, call4, radius)
response4 <- GET(uri4)
body4 <- content(response4, "text")
parsed_body4 <- fromJSON(body4)
data4 <- data.frame(parsed_body4$data$list, stringsAsFactors = FALSE)
data4 <- data4 %>%
select(lon, lat)
#myLocation <- ("University of Washington")
#geocode <- geocode(myLocation)
#myMap <- get_map(location = myLocation, source = "google", maptype = "roadmap",
crop = FALSE)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = data1,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data2,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data3,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data4,
alpha = 1, color="black", size = 1) +
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = data1,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data2,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data3,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data4,
alpha = 1, color="black", size = 1)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = data1,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data2,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data3,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data4,
alpha = 1, color="black", size = 1)
uri4 <- paste0(baseuri, topic, key, call4, radius)
response4 <- GET(uri4)
body4 <- content(response4, "text")
parsed_body4 <- fromJSON(body4)
data4 <- data.frame(parsed_body4$data$list, stringsAsFactors = FALSE)
data4 <- data4 %>%
select(lon, lat)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = data1,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data2,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data3,
alpha = 1, color="black", size = 1) +
geom_point(aes(x = lon, y = lat), data = data4,
alpha = 1, color="black", size = 1)
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_44.xml?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
library(jsonlite)
library(httr)
library(knitr)
library(dplyr)
library(ggplot2)
library(ggmap)
library(mapdata)
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_44.xml?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body1 <- content(response1, "text")
parsed_body1 <- fromJSON(body1)
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_44.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
body1 <- content(response1, "text")
parsed_body1 <- fromJSON(body1)
data1 <- data.frame(parsed_body1$data$list, stringsAsFactors = FALSE)
View(parsed_body1)
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1.jsdon?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
body1 <- content(response1, "text")
parsed_body1 <- fromJSON(body1)
library(jsonlite)
library(httr)
library(knitr)
library(dplyr)
library(ggplot2)
library(ggmap)
library(mapdata)
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1.jsdon?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1.jsdon?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
View(response1)
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1_70.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1_70.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1_70.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1_44.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1_44.xml?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1_44.xml?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/route-ids-for-agency/1_44.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/routes-for-agency/1.xml?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
body1 <- content(response1, "text")
parsed_body1 <- fromJSON(body1)
response1 <- GET("http://api.pugetsound.onebusaway.org/api/where/routes-for-agency/1.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
body1 <- content(response1, "text")
parsed_body1 <- fromJSON(body1)
data1 <- data.frame(parsed_body1$data$list, stringsAsFactors = FALSE)
View(data1)
response_routes <- GET("http://api.pugetsound.onebusaway.org/api/where/routes-for-agency/1.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
body_routes <- content(response_routes, "text")
response_routes <- GET("http://api.pugetsound.onebusaway.org/api/where/routes-for-agency/1.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
body_routes <- content(response_routes, "text")
parsed_body_routes <- fromJSON(body_routes)
routes <- data.frame(parsed_body_routes$data$list, stringsAsFactors = FALSE)
View(routes)
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264.json?key=key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body_70 <- content(response_70, "text")
parsed_body_70 <- fromJSON(body_70)
routes_70 <- data.frame(parsed_body_70$data$list, stringsAsFactors = FALSE)
View(response_70)
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body_70 <- content(response_70, "text")
parsed_body_70 <- fromJSON(body_70)
routes_70 <- data.frame(parsed_body_70$data$list, stringsAsFactors = FALSE)
View(parsed_body_70)
routes_70 <- data.frame(parsed_body_70$data$references$stops, stringsAsFactors = FALSE)
View(routes_70)
routes_70 <- routes_70 %>%
select(lat, lon)
myLocation <- ("University of Washington")
geocode <- geocode(myLocation)
myMap <- get_map(location = myLocation, source = "google", maptype = "roadmap",
crop = FALSE)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="black", size = 1)
myLocation <- ("University of Washington")
geocode <- geocode(myLocation)
myMap <- get_map(location = myLocation, source = "google", maptype = "roadmap",
crop = FALSE)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="black", size = 1)
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body_70 <- content(response_70, "text")
parsed_body_70 <- fromJSON(body_70)
routes_70 <- data.frame(parsed_body_70$data$references$stops, stringsAsFactors = FALSE)
View(routes)
## Uncomment this to install packages
install.packages('rvest')
# Load in 'rvest' package
library('rvest')
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
webpage <- read_html(url)
rank_data_html <- html_nodes(webpage,'.text-primary')
rank_data <- html_text(rank_data_html)
head(rank_data)
rank_data<-as.numeric(rank_data)
head(rank_data)
#Using CSS selectors to scrape the title section
title_data_html <- html_nodes(webpage, '.lister-item-header a')
#html to text
title_data <- html_text(title_data_html)
#look at data
head(title_data)
#Using CSS selectors to scrape the description section
description_data_html <- html_nodes(webpage, '.ratings-bar+ .text-muted')
#Converting the description data to text
description_data <- html_text(description_data_html)
#look at data
description_data
#look at data
head(description_data)
#Data-Preprocessing: removing '\n'
description_data <- gsub("\n", "", description_data)
head(description_data)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="red", size = 0.5)
response_routes <- GET("http://api.pugetsound.onebusaway.org/api/where/routes-for-agency/1.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20")
body_routes <- content(response_routes, "text")
parsed_body_routes <- fromJSON(body_routes)
routes <- data.frame(parsed_body_routes$data$list, stringsAsFactors = FALSE)
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body_70 <- content(response_70, "text")
parsed_body_70 <- fromJSON(body_70)
routes_70 <- data.frame(parsed_body_70$data$references$stops, stringsAsFactors = FALSE)
routes_70 <- routes_70 %>%
select(lat, lon)
myLocation <- ("University of Washington")
geocode <- geocode(myLocation)
myMap <- get_map(location = myLocation, source = "google", maptype = "roadmap",
crop = FALSE)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="red", size = 0.5)
ggmap(myMap) +
geom_point(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="black", size = 0.5)
ggmap(myMap) +
geom_line(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="black", size = 0.5) +
ggmap(myMap) +
geom_line(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="black", size = 0.5)
ggmap(myMap) +
geom_line(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="black", size = 0.5)
install.packages('syuzhet')
library(syuzhet)
library(syuzhet)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!'
)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!'
)
# Analyze sentiment for student sentences
get_sentiment(student_sentences)
# Analyze sentiment for student sentences
get_sentiment(student_sentences, method = 'syuzhet')
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!'
'I hate you'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I hate you'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I hate you.'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I hate you so much'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
student_analysis <- cbind(sentence = student_sentences, sentiment = student_sentiments)
student_analysis
# install.packages('dplyr')
# install.packages('stringr')
install.packages('tidytext')
library(dplyr)
library(stringr)
library(tidytext)
library(tidyr)
library(ggplot2)
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
get_sentiments("nrc")
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
View(get_sentiments("nrc"))
View(get_sentiments("afinn"))
View(get_sentiments("bing"))
bing_sentiments <- get_sentiments("bing")
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv('./data/austenbooks.csv')
setwd("C:/Users/brook/Desktop/Git/mini-demos/sentiment_analysis")
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv('./data/austenbooks.csv')
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv('./data/austen_books.csv')
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv('./data/austen_books.csv', stringsAsFactors = FALSE)
# Map each word in the 'books' dataset to its dictionary-prescribed sentiment.
jane_austen_sentiment <- books %>%
inner_join(bing_sentiments, by = "word")
View(jane_austen_sentiment)
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
View(jane_austen_sentiment)
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
# Map each word in the 'books' dataset to its dictionary-prescribed sentiment.
jane_austen_sentiment <- books %>%
inner_join(bing_sentiments, by = "word")
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
##### CREATE OUR VISUALIZATION #####
# Use ggplot to plot each chapter's sentiment by book.
ggplot(data = jane_austen_sentiment) +
geom_bar(mapping = aes(chapter, sentiment, fill = book)) +
geom_col(show.legend = FALSE)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I hate you so much'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
student_analysis <- cbind(sentence = student_sentences, sentiment = student_sentiments)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I hate you and you smell bad.'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
student_analysis <- cbind(sentence = student_sentences, sentiment = student_sentiments)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I hate you and you smell bad you ugly trool, booyah'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
student_analysis <- cbind(sentence = student_sentences, sentiment = student_sentiments)
student_analysis
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I hate you and you smell bad you ugly trool, booyah',
'Booyah'
)
# Analyze sentiment for student sentences
student_sentiments <- get_sentiment(student_sentences, method = 'syuzhet')
student_sentiments
student_analysis <- cbind(sentence = student_sentences, sentiment = student_sentiments)
student_analysis
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264&1_100228
.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264&.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
#load library
library(class) #Has the knn function
#loading data
data("iris")
#loading data
data("iris")
View(iris)
#Set the seed for reproducibility
set.seed(4948493)
#Sample the Iris data set (70% train, 30% test)
ir_sample <- sample(1:nrow(iris),size=nrow(iris)*.7)
ir_train <- iris[ir_sample,] #Select the 70% of rows
ir_test <- iris[-ir_sample,] #Select the 30% of rows
#Find Accuracy of Prediction
accuracy = function(actual, predicted) {
mean(actual == predicted)
}
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 40)
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 40)
accuracy(ir_test$Species, pred)
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 4)
accuracy(ir_test$Species, pred)
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 5)
accuracy(ir_test$Species, pred)
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 6)
accuracy(ir_test$Species, pred)
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 7)
accuracy(ir_test$Species, pred)
#LOOP FOR MULTIPLE K's
k_to_try = 1:100
acc_k = rep(x = 0, times = length(k_to_try))
for(i in seq_along(k_to_try)) {
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = k_to_try[i])
acc_k[i] <- accuracy(ir_test$Species, pred)
}
plot(acc_k, type = "b", col = "dodgerblue", cex = 1, pch = 20,
xlab = "k, number of neighbors", ylab = "classification accuracy",
main = "Accuracy vs Neighbors")
# add lines indicating k with best accuracy
abline(v = which(acc_k == max(acc_k)), col = "darkorange", lwd = 1.5)
# add line for max accuracy seen
abline(h = max(acc_k), col = "grey", lty = 2)
acc_k[i] <- accuracy(ir_test$Species, pred)
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = k_to_try[i])
install_keras()
# First, install the keras R package from GitHub as follows:
devtools::install_github("rstudio/keras")
# The Keras R interface uses the TensorFlow backend engine by default.
# To install both the core Keras library as well as the TensorFlow backend use the install_keras() function:
library(keras)
ggmap(myMap) +
geom_line(aes(x = lon, y = lat), data = routes_70,
alpha = 1, color="black", size = 0.5)
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264&.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body_70 <- content(response_70, "text")
parsed_body_70 <- fromJSON(body_70)
routes_70 <- data.frame(parsed_body_70$data$references$stops, stringsAsFactors = FALSE)
routes_70 <- routes_70 %>%
select(lat, lon)
routes_70 <- data.frame(parsed_body_70$data$references$stops, stringsAsFactors = FALSE)
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264&.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body_70 <- content(response_70, "text")
parsed_body_70 <- fromJSON(body_70)
routes_70 <- data.frame(parsed_body_70$data$references$stops, stringsAsFactors = FALSE)
View(routes_70)
rm(body_70, parsed_body_70, response_70)
response_70 <- GET("http://api.pugetsound.onebusaway.org/api/where/stops-for-route/1_100264.json?key=5e4ce2b2-47af-4645-b064-bffb6632ae20&version=2")
body_70 <- content(response_70, "text")
parsed_body_70 <- fromJSON(body_70)
routes_70 <- data.frame(parsed_body_70$data$references$stops, stringsAsFactors = FALSE)
rm(body_70, parsed_body_70, response_70)
